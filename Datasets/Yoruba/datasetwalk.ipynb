{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "import json\n",
    "from pydub.utils import mediainfo\n",
    "import wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definining the directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"D:/ProgrammingWork/XRI-Global-Internship/Yoruba\"\n",
    "clips_dir = os.path.join(base_dir, \"clips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dirs = {\n",
    "    \"train\": os.path.join(base_dir, \"structured/train\"),\n",
    "    \"dev\": os.path.join(base_dir, \"structured/dev\"),\n",
    "    \"test\": os.path.join(base_dir, \"structured/test\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to process a dataset split by converting audio files and saving transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_split(file_path, split_name):\n",
    "    data = pd.read_csv(file_path, sep='\\t')  # Load .tsv file\n",
    "    output_dir = output_dirs[split_name]\n",
    "\n",
    "    # Loop over each row in the DataFrame\n",
    "    for _, row in data.iterrows():\n",
    "        clip_id = row['path']\n",
    "        transcription = row['sentence']\n",
    "        \n",
    "        # Define paths for input clip and output converted clip\n",
    "        clip_path = os.path.join(clips_dir, clip_id)\n",
    "        wav_output_path = os.path.join(output_dir, os.path.splitext(clip_id)[0] + \".wav\")\n",
    "\n",
    "        # Convert MP3 to WAV at 16kHz\n",
    "        audio = AudioSegment.from_mp3(clip_path)\n",
    "        audio = audio.set_frame_rate(16000).set_channels(1)\n",
    "        audio.export(wav_output_path, format=\"wav\")\n",
    "\n",
    "        # Save transcription to a text file\n",
    "        transcription_path = os.path.join(output_dir, os.path.splitext(clip_id)[0] + \".txt\")\n",
    "        with open(transcription_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_split(os.path.join(base_dir, \"train.tsv\"), \"train\")\n",
    "process_split(os.path.join(base_dir, \"dev.tsv\"), \"dev\")\n",
    "process_split(os.path.join(base_dir, \"test.tsv\"), \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a JSON path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(file_path):\n",
    "    \"\"\"Get the duration of an audio file in seconds.\"\"\"\n",
    "    info = mediainfo(file_path)\n",
    "    return float(info['duration'])\n",
    "\n",
    "def create_asr_json(audio_dir, output_json_path):\n",
    "    json_data = []\n",
    "\n",
    "    # Loop through each .wav file in the directory\n",
    "    for wav_file in os.listdir(audio_dir):\n",
    "        if wav_file.endswith(\".wav\"):\n",
    "            wav_path = os.path.join(audio_dir, wav_file)\n",
    "            txt_path = os.path.join(audio_dir, os.path.splitext(wav_file)[0] + \".txt\")\n",
    "            \n",
    "            # Read the transcription\n",
    "            if os.path.exists(txt_path):\n",
    "                with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "                    transcription = f.read().strip()\n",
    "                \n",
    "                # Get the duration of the audio file\n",
    "                duration = get_duration(wav_path)\n",
    "\n",
    "                # Construct JSON entry\n",
    "                json_data.append({\n",
    "                    \"audio_filepath\": os.path.relpath(wav_path, base_dir),\n",
    "                    \"text\": transcription,\n",
    "                    \"duration\": duration\n",
    "                })\n",
    "\n",
    "    # Write JSON data to file\n",
    "    with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(json_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.join(os.getcwd(), \"structured\") \n",
    "create_asr_json(os.path.join(base_dir, \"train\"), os.path.join(base_dir, \"train.json\"))\n",
    "create_asr_json(os.path.join(base_dir, \"dev\"), os.path.join(base_dir, \"dev.json\"))\n",
    "create_asr_json(os.path.join(base_dir, \"test\"), os.path.join(base_dir, \"test.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running tests for various formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_audio_properties(audio_dir, sample_rate=16000, channels=1, bit_depth=2):\n",
    "    for wav_file in os.listdir(audio_dir):\n",
    "        if wav_file.endswith(\".wav\"):\n",
    "            with wave.open(os.path.join(audio_dir, wav_file), 'r') as wf:\n",
    "                assert wf.getframerate() == sample_rate, f\"{wav_file} has a sample rate of {wf.getframerate()}, expected {sample_rate}\"\n",
    "                assert wf.getnchannels() == channels, f\"{wav_file} is not mono, expected {channels} channels\"\n",
    "                assert wf.getsampwidth() == bit_depth, f\"{wav_file} is not 16-bit, expected bit depth {bit_depth}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir_train = \"structured/train\"\n",
    "check_audio_properties(audio_dir_train)\n",
    "\n",
    "audio_dir_test = \"structured/test\"\n",
    "check_audio_properties(audio_dir_test)\n",
    "\n",
    "audio_dir_dev = \"structured/dev\"\n",
    "check_audio_properties(audio_dir_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking what the split of data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1246, Total duration: 2.10 hours\n",
      "Total samples: 1014, Total duration: 1.74 hours\n",
      "Total samples: 874, Total duration: 1.29 hours\n"
     ]
    }
   ],
   "source": [
    "def summarize_dataset(json_path):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        total_duration = sum(entry[\"duration\"] for entry in data)\n",
    "        print(f\"Total samples: {len(data)}, Total duration: {total_duration / 3600:.2f} hours\")\n",
    "\n",
    "summarize_dataset(\"structured/train.json\")\n",
    "summarize_dataset(\"structured/test.json\")\n",
    "summarize_dataset(\"structured/dev.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
