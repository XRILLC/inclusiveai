{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3a116ca",
   "metadata": {
    "id": "c3a116ca"
   },
   "source": [
    "# Neural Machine Translation â€” Experiments\n",
    "Workbook for experimenting with small scale systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pVyQWhjCtm9t",
   "metadata": {
    "id": "pVyQWhjCtm9t"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install watermark\n",
    "!pip install evaluate\n",
    "!pip install sacrebleu\n",
    "!pip install sacremoses\n",
    "!pip install wandb\n",
    "!pip install peft\n",
    "!pip install transformers sentencepiece\n",
    "!pip install -U transformers\n",
    "# !pip install --force-reinstall --upgrade --no-cache-dir --no-deps unsloth unsloth_zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89db3681",
   "metadata": {
    "id": "89db3681"
   },
   "source": [
    "## 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Da0ZH-vBfZA9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Da0ZH-vBfZA9",
    "outputId": "7faf17c7-fe1b-4903-8b90-f5cc8639415e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwzmatt\u001b[0m (\u001b[33mwzmatt-university-of-arizona\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "def is_colab():\n",
    "  try:\n",
    "    import google.colab\n",
    "\n",
    "    return True\n",
    "  except ImportError as e:\n",
    "    print(f\"{e}\", end='')\n",
    "    return False\n",
    "\n",
    "google_colab = is_colab()\n",
    "\n",
    "if google_colab:\n",
    "    from google.colab import drive, userdata\n",
    "    from huggingface_hub import login\n",
    "    import wandb\n",
    "\n",
    "    drive.mount('/content/gdrive')\n",
    "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
    "    WAND_TOKEN = userdata.get('wandb')\n",
    "\n",
    "    login(token=HF_TOKEN)\n",
    "    wandb.login(key=WAND_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b5343",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "182b5343",
    "outputId": "a2ea2b0c-0878-471b-bd71-9796977a998e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Matthew\n",
      "\n",
      "Last updated: 2025-03-31\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.11\n",
      "IPython version      : 7.34.0\n",
      "\n",
      "pandas         : 2.2.2\n",
      "evaluate       : 0.4.3\n",
      "torch          : 2.6.0+cu124\n",
      "numpy          : 2.0.2\n",
      "datasets       : 3.5.0\n",
      "transformers   : 4.50.3\n",
      "wandb          : 0.19.8\n",
      "accelerate     : 1.5.2\n",
      "huggingface_hub: 0.29.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from time import perf_counter\n",
    "from tkinter import filedialog\n",
    "import pdb\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset, get_dataset_config_names, Dataset, DatasetDict, concatenate_datasets\n",
    "import accelerate\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from peft import PeftModelForSeq2SeqLM, get_peft_config\n",
    "from transformers import (\n",
    "    MarianMTModel, MarianTokenizer, MarianConfig,\n",
    "    Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "%watermark -a \"Matthew\" -d -u -v -p pandas,evaluate,torch,numpy,datasets,transformers,wandb,accelerate,huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad0b990",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ad0b990",
    "outputId": "f75cb860-7587-48c6-9765-e172c380a8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device cuda is being used.\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "  \"\"\"Configuration for machine translation experiments. Intended to be reconfigurated for each run.\"\"\"\n",
    "  seed: int = 42\n",
    "\n",
    "  source_lang: str = \"en\"\n",
    "  target_lang: str = \"es\"\n",
    "  cache_dir: str = \"./gdrive/MyDrive/translation/\"\n",
    "\n",
    "  dataset: str = \"weezygeezer/Spanish-Asturian_Parallel-Corpus\"\n",
    "  task_prefix: str = \">>spa<< \"\n",
    "  task_prefix_2: str = \">>ast<< \"\n",
    "  label_pad_token_id: int = \"\"\n",
    "  max_source_length: int = 512\n",
    "  max_target_length: int = 512\n",
    "  model_max_length: int = 0\n",
    "\n",
    "  batch_size: int = 1\n",
    "  lr: float = 1e-4\n",
    "  num_epochs: int  = 5\n",
    "  weight_decay: float = 0.01\n",
    "  num_beams: int = 4\n",
    "  save_steps: int = 20_000\n",
    "\n",
    "  model_checkpoint = 'Helsinki-NLP/opus-mt-tc-bible-big-deu_eng_fra_por_spa-itc'\n",
    "  device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  do_train: bool = True\n",
    "\n",
    "  def __post_init__(self):\n",
    "      \"\"\"Sets the random seed upon class creation.\"\"\"\n",
    "      random.seed(self.seed)\n",
    "      np.random.seed(42)\n",
    "      torch.manual_seed(self.seed)\n",
    "      torch.cuda.manual_seed_all(self.seed)\n",
    "      set_seed(self.seed)\n",
    "\n",
    "      print(f\"The device {self.device} is being used.\", end=\"\\n\")\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OdTL3GKb-CIW",
   "metadata": {
    "id": "OdTL3GKb-CIW"
   },
   "outputs": [],
   "source": [
    "model_name = config.model_checkpoint.split(\"/\")[-1]\n",
    "output_dir = os.path.join(config.cache_dir, f\"{model_name}_{config.source_lang}-{config.target_lang}\")\n",
    "\n",
    "fine_tuned_model_checkpoint = os.path.join(\n",
    "    output_dir,\n",
    "    \"checkpoint\")\n",
    "\n",
    "def make_dir():\n",
    "  try:\n",
    "    os.makedirs(fine_tuned_model_checkpoint, exist_ok=False)\n",
    "    print(f\"Directory {fine_tuned_model_checkpoint} created.\")\n",
    "  except OSError as error:\n",
    "    shutil.rmtree(fine_tuned_model_checkpoint)\n",
    "    os.makedirs(fine_tuned_model_checkpoint, exist_ok=False)\n",
    "    print(f\"The previous {fine_tuned_model_checkpoint} directory was removed to create new directory.\")\n",
    "\n",
    "# make_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcf79ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "0b8762faec424a32a811c54f9e0b3a63",
      "d7a21fc8b12645708e6791da1fe6817c",
      "496962e42ddb44eb878b6423e90982c6",
      "81f0e504ec154702af569223822659a9",
      "cd1e7589d550429fb5a7277ae0d90edd",
      "99ac00d3db264388bb6359efc07d717b",
      "3c0159f979664d46ad5095e709e5fae6",
      "beb57997ac024c8090d4246bfc2dc488",
      "625af4d11ffd4e6f94616b1ddefdd0b2",
      "508e5c2269384b4186ccc717edd364f1",
      "6e63e03e01254fec886ae9b677d2616e",
      "e12dd632c89d4cebb7da8056dee718b7",
      "f37965263e59400280c24dbcead2655f",
      "eab117d7d1b94c078b26c4d4a7beecbe",
      "a82f3a5ecb0f46309f0ed010ede36b38",
      "6d541e719b794df3ba3ed794df31e285",
      "0882e6e5b2634c46922b2401b5e918d2",
      "bf1d989ae5a141929bcc083d31dbc246",
      "9e1c57e0b36f482d821783b6e27bfaf6",
      "0c3ea1c8b56f4ae6a4f4f12a85af92ff",
      "bb67ec0d97c14480990513fdfaa93fa5",
      "b1c8f731bc724190becc60ced1403608",
      "b503e3a754b64b229188ad2ee9839889",
      "442ba8e959434f298a616c3cd420d210",
      "4f501595ec1d4726ad8bc2d942721303",
      "b14cc6e6e2c84f86819083cb38bb9a0c",
      "357dc926d47b4cbdad77e8e24d53cf60",
      "bc6de8151730430db886a52c5d4bc2a0",
      "c5ca92e74a854b0e80d6918460f4a333",
      "bfe4989e7bde4de8acfa3b74576ac522",
      "1cf22ecfb5c243d4bcd1c7e079f89e07",
      "05b5ecb49ddd48759a1f6976edc346a1",
      "b854d78cccd64b9db18bf8b33a3f0443",
      "05bdeca04a014fbbbff0f15dab0f7477",
      "f0eca787bde04f008c144f40ca60e0f8",
      "58a492eac5c6433c9b7a4c9d6e4bcbc2",
      "f712b33603be497f8194adc2eb386ca8",
      "05d2d49db2374f13bab2cd21dcc3a068",
      "c33e20e0185343cfbe1ce0eac471960b",
      "ffdbb15d56704319b9dd391d360185b5",
      "c3b15927f1f44a8cb825408edf926a47",
      "2cfc10305d3e49b7ababde59df02d436",
      "0cefb63c6c9b4637ac3bae53da5b8684",
      "dcdf9eb45aa742689c9cd02e23f1e4cd",
      "92bccd3e7dd84737919326867792fe3d",
      "3d47f22681234d529c4dbff03038c589",
      "ab4abcfa69aa404e8bcff6c92c2bb2e3",
      "6c4ccfba78354d039c0dd78cd3398885",
      "6269848891224b0f9f4f4606d12fde41",
      "6c3d2e7f6f214783be21cb22671c00bd",
      "b602af2c20594a84a2d77433877eec78",
      "b642216323b046a8a29fd06d698c8c12",
      "c567176339474a2db06970303d87addb",
      "0d948c7460d848ae9a289880381535cc",
      "af191a8de1ee4624b74e1a6f319e67b0"
     ]
    },
    "id": "1dcf79ec",
    "outputId": "9ffa60d6-7ee5-4e36-fc27-8cf1c2dd568d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8762faec424a32a811c54f9e0b3a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/9.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12dd632c89d4cebb7da8056dee718b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b503e3a754b64b229188ad2ee9839889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bdeca04a014fbbbff0f15dab0f7477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bccd3e7dd84737919326867792fe3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chrf = evaluate.load('chrf', cache_dir=config.cache_dir)\n",
    "bleu_score = evaluate.load('bleu', cache_dir=config.cache_dir)\n",
    "sacrebleu_score = evaluate.load('sacrebleu', cache_dir=config.cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UpgpHe_rTFBJ",
   "metadata": {
    "id": "UpgpHe_rTFBJ"
   },
   "outputs": [],
   "source": [
    "def generate_translation(batch):\n",
    "  \"\"\"\n",
    "  Translation function for evaluation.\n",
    "  \"\"\"\n",
    "  inputs = [x for x in batch[config.source_lang]]\n",
    "  inputs = [config.task_prefix_2 + x for x in inputs]\n",
    "\n",
    "  encoded = tokenizer(\n",
    "      inputs,\n",
    "      max_length=tokenizer.model_max_length,\n",
    "      truncation=True,\n",
    "      padding=True,\n",
    "      return_tensors='pt',\n",
    "  )\n",
    "\n",
    "  input_ids = encoded.input_ids.to(device)\n",
    "  attention_mask = encoded.attention_mask.to(device)\n",
    "\n",
    "  output = translator.generate(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      num_beams=4,\n",
    "      max_length=tokenizer.model_max_length,\n",
    "  )\n",
    "\n",
    "  decoded = tokenizer.batch_decode(\n",
    "      output,\n",
    "      skip_special_tokens=True\n",
    "  )\n",
    "\n",
    "  targets = [x for x in batch[config.target_lang]]\n",
    "\n",
    "  return {\n",
    "      'reference': targets,\n",
    "      'prediction': decoded\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_lSk6CcSYSHi",
   "metadata": {
    "id": "_lSk6CcSYSHi"
   },
   "outputs": [],
   "source": [
    "def generate_backtranslation(batch):\n",
    "  \"\"\"\n",
    "  Function for backtranslation.\n",
    "  **Notably, the reference is the source language.**\n",
    "  \"\"\"\n",
    "  inputs = [x for x in batch[config.source_lang]]\n",
    "  references = inputs.copy()\n",
    "  inputs = [task_prefix_2 + x for x in inputs]\n",
    "\n",
    "  encoded = tokenizer(\n",
    "      inputs,\n",
    "      max_length=tokenizer.model_max_length,\n",
    "      truncation=True,\n",
    "      padding=True,\n",
    "      return_tensors='pt',\n",
    "  )\n",
    "\n",
    "  input_ids = encoded.input_ids.to(device)\n",
    "  attention_mask = encoded.attention_mask.to(device)\n",
    "\n",
    "  output = translator.generate(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      num_beams=4,\n",
    "      max_length=tokenizer.model_max_length,\n",
    "  )\n",
    "\n",
    "  decoded = tokenizer.batch_decode(\n",
    "      output,\n",
    "      skip_special_tokens=True,\n",
    "  )\n",
    "\n",
    "  return {\n",
    "      \"reference\": references,\n",
    "      \"prediction\": decoded,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qDFkaI96Y16s",
   "metadata": {
    "id": "qDFkaI96Y16s"
   },
   "outputs": [],
   "source": [
    "def backtranslate(batch):\n",
    "  inputs = [x for x in batch['asturian']]\n",
    "  inputs = [task_prefix + x for x in inputs]\n",
    "\n",
    "  encoded = tokenizer(\n",
    "      inputs,\n",
    "      max_length=tokenizer.model_max_length,\n",
    "      truncation=True,\n",
    "      padding=True,\n",
    "      return_tensors='pt',\n",
    "      )\n",
    "\n",
    "  input_ids = encoded.input_ids.to(device)\n",
    "  attention_mask = encoded.attention_mask.to(device)\n",
    "\n",
    "  output = translator.generate(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      num_beams=1,\n",
    "      max_length=tokenizer.model_max_length,\n",
    "      )\n",
    "\n",
    "  decoded = tokenizer.batch_decode(\n",
    "      output,\n",
    "      skip_special_tokens=True\n",
    "      )\n",
    "\n",
    "  targets = [x for x in batch['asturian']]\n",
    "\n",
    "  return {\n",
    "      source: decoded,\n",
    "      target: targets,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wehV5g4_oRiX",
   "metadata": {
    "id": "wehV5g4_oRiX"
   },
   "source": [
    "## 0. Backtranslation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0uFdArsLoWrz",
   "metadata": {
    "id": "0uFdArsLoWrz"
   },
   "outputs": [],
   "source": [
    "backtranslation = False\n",
    "source = 'Spanish'\n",
    "target = 'Asturian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6U1kzfgUouJF",
   "metadata": {
    "id": "6U1kzfgUouJF"
   },
   "outputs": [],
   "source": [
    "if backtranslation:\n",
    "  device = torch.device('cuda')\n",
    "  task_prefix = \">>spa<< \"\n",
    "  # model_name = 'Helsinki-NLP/opus-mt-tc-bible-big-roa-deu_eng_fra_por_spa'\n",
    "  model_name = 'Helsinki-NLP/opus-mt-tc-bible-big-itc-fra_ita_por_spa'\n",
    "  translator = MarianMTModel.from_pretrained(model_name)\n",
    "  translator.to(device)\n",
    "  tokenizer = MarianTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ap0h4XsmpGUT",
   "metadata": {
    "id": "Ap0h4XsmpGUT"
   },
   "outputs": [],
   "source": [
    "if backtranslation:\n",
    "  monolingual_corpus = 'literary_cln.ast'\n",
    "  dataset = load_dataset(path='csv', data_files=monolingual_corpus, encoding='utf-8',\n",
    "                       delimiter='\\t', column_names=['asturian', 'idx'],\n",
    "                       split='train')\n",
    "  dataset = dataset.remove_columns('idx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pqQMkbdKvufO",
   "metadata": {
    "id": "pqQMkbdKvufO"
   },
   "outputs": [],
   "source": [
    "def backtranslate(batch):\n",
    "  inputs = [x for x in batch['asturian']]\n",
    "  inputs = [task_prefix + x for x in inputs]\n",
    "\n",
    "  encoded = tokenizer(\n",
    "      inputs,\n",
    "      max_length=tokenizer.model_max_length,\n",
    "      truncation=True,\n",
    "      padding=True,\n",
    "      return_tensors='pt',\n",
    "      )\n",
    "\n",
    "  input_ids = encoded.input_ids.to(device)\n",
    "  attention_mask = encoded.attention_mask.to(device)\n",
    "\n",
    "  output = translator.generate(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      num_beams=1,\n",
    "      max_length=tokenizer.model_max_length,\n",
    "      )\n",
    "\n",
    "  decoded = tokenizer.batch_decode(\n",
    "      output,\n",
    "      skip_special_tokens=True\n",
    "      )\n",
    "\n",
    "  targets = [x for x in batch['asturian']]\n",
    "\n",
    "  return {\n",
    "      source: decoded,\n",
    "      target: targets,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "giO1nqIjA2dK",
   "metadata": {
    "id": "giO1nqIjA2dK"
   },
   "outputs": [],
   "source": [
    "if backtranslation:\n",
    "  results = dataset.map(\n",
    "      backtranslate,\n",
    "      batched=True,\n",
    "      batch_size=125,\n",
    "      remove_columns=dataset.column_names\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7hcgvL2Wpkxf",
   "metadata": {
    "id": "7hcgvL2Wpkxf"
   },
   "outputs": [],
   "source": [
    "if backtranslation:\n",
    "  test = results.to_pandas()\n",
    "  test.to_csv('literary_bitext.csv', header=True, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rrK7XpWGgCHi",
   "metadata": {
    "id": "rrK7XpWGgCHi"
   },
   "source": [
    "## 0. Load train & evaluation (Flores)\n",
    "- datasets should already be filtered during this process\n",
    "- depending on target language, can use flores, opus, or a held-out dataset for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DD63Le0DYB0H",
   "metadata": {
    "id": "DD63Le0DYB0H"
   },
   "outputs": [],
   "source": [
    "def extract_langs(row):\n",
    "  return {\n",
    "      \"en\": row['translation'].get(\"en\", \"\"),\n",
    "      \"es\": row['translation'].get(\"es\", \"\")\n",
    "  }\n",
    "\n",
    "def create_flores(flores, pair):\n",
    "  evaluation = {}\n",
    "\n",
    "  for eval in flores:\n",
    "    dev_src = flores[eval].filter(lambda x: x['iso_639_3'].startswith(pair['src'][0]))\n",
    "    dev_tgt = flores[eval].filter(lambda x: x['iso_639_3'].startswith(pair['tgt'][0]))\n",
    "    assert len(dev_src) == len(dev_tgt)\n",
    "\n",
    "    eval_ds = Dataset.from_dict(\n",
    "        {pair['src'][1]: dev_src['text'],\n",
    "         pair['tgt'][1]: dev_tgt['text']}\n",
    "    )\n",
    "    evaluation[eval] = eval_ds\n",
    "\n",
    "  return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HcKb6oYx6luB",
   "metadata": {
    "id": "HcKb6oYx6luB"
   },
   "outputs": [],
   "source": [
    "dev_ast = load_dataset('text', data_files='gdrive/MyDrive/translation/FLORES+/dev/dev.ast_Latn', split='train')\n",
    "dev_spa = load_dataset('text', data_files='gdrive/MyDrive/translation/FLORES+/dev/dev.spa_Latn', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vggNhUOX6ux8",
   "metadata": {
    "id": "vggNhUOX6ux8"
   },
   "outputs": [],
   "source": [
    "dev_ast = dev_ast.rename_column('text', 'ast')\n",
    "dev_spa = dev_spa.rename_column('text', 'es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VGMq1Fmc9iII",
   "metadata": {
    "id": "VGMq1Fmc9iII"
   },
   "outputs": [],
   "source": [
    "dev_ds = concatenate_datasets([dev_spa, dev_ast], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EdTHexZKYI_u",
   "metadata": {
    "id": "EdTHexZKYI_u"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# flores = load_dataset('openlanguagedata/flores_plus')\n",
    "\n",
    "# pair = {'src': ('spa', 'es'), 'tgt': ('ast', 'ast')}\n",
    "# flores_eval = create_flores(flores, pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P-xSWJEkgNad",
   "metadata": {
    "id": "P-xSWJEkgNad"
   },
   "outputs": [],
   "source": [
    "# dev_ds = flores_eval['dev']\n",
    "# devtest_ds = flores_eval['devtest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LiJ8ng9jqob_",
   "metadata": {
    "id": "LiJ8ng9jqob_"
   },
   "outputs": [],
   "source": [
    "train_ds = load_dataset(config.dataset, split=\"GNOME+KDE4+OpenSubtitles+PILARcrawled+PILARliterary+Tatoeba+wikimedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wVmhJKjjsDTR",
   "metadata": {
    "id": "wVmhJKjjsDTR"
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.rename_column('Spanish', 'es')\n",
    "train_ds = train_ds.rename_column('Asturian', 'ast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WcsVpm3tqAio",
   "metadata": {
    "id": "WcsVpm3tqAio"
   },
   "outputs": [],
   "source": [
    "dataset_dict = DatasetDict({'train': train_ds,\n",
    "             'dev': dev_ds,\n",
    "            #  'devtest': devtest_ds\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6_Jf68xmlth",
   "metadata": {
    "id": "a6_Jf68xmlth"
   },
   "outputs": [],
   "source": [
    "# dataset_dict['dev'] = dev_ds\n",
    "# dataset_dict['devtest'] = devtest_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n9NwfVJ2mug0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9NwfVJ2mug0",
    "outputId": "b4fd7468-4efb-4fe5-fd67-c97cf9a6758b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['es', 'ast'],\n",
       "        num_rows: 122449\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['es', 'ast'],\n",
       "        num_rows: 997\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4SdGQfz3gKwb",
   "metadata": {
    "id": "4SdGQfz3gKwb"
   },
   "source": [
    "## 1. Baseline System\n",
    "- Apertium\n",
    "- Baseline (zero-shot translation/cross-lingual transfer)\n",
    "  - Marian MT: roa-en, big-mul-mul, and big-roa-few\n",
    "  - Performance: https://opus.nlpl.eu/dashboard/index.php?pkg=opusmt&test=all&scoreslang=all&chart=standard&model=Tatoeba-MT-models/mul-mul/opusTCv20230926%2Bbt%2Bjhubc_transformer-big_2024-08-17\n",
    "  - https://huggingface.co/Helsinki-NLP/opus-mt-tc-bible-big-mul-mul\n",
    "  - https://huggingface.co/docs/transformers/en/model_doc/marian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EH5WyKcDgbTw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EH5WyKcDgbTw",
    "outputId": "3812c879-9897-405a-d2a2-f6f9da8f3317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device cuda is being used.\n"
     ]
    }
   ],
   "source": [
    "baseline = True\n",
    "\n",
    "if baseline:\n",
    "  baseline_config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sZ19iuOigeIe",
   "metadata": {
    "id": "sZ19iuOigeIe"
   },
   "outputs": [],
   "source": [
    "if baseline:\n",
    "  baseline_config.model_checkpoint = 'Helsinki-NLP/opus-mt-tc-bible-big-deu_eng_fra_por_spa-itc'\n",
    "  baseline_config.source_lang = 'es'\n",
    "  baseline_config.target_lang = 'ast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6lLd0240MYH9",
   "metadata": {
    "id": "6lLd0240MYH9"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "if baseline:\n",
    "  tokenizer = MarianTokenizer.from_pretrained(baseline_config.model_checkpoint)\n",
    "  model = MarianMTModel.from_pretrained(baseline_config.model_checkpoint)\n",
    "  model.to(baseline_config.device)\n",
    "\n",
    "  baseline_config.model_max_length = tokenizer.model_max_length\n",
    "  baseline_config.task_prefix = \">>spa<< \" #may need to test again because the space wasn't included ?\n",
    "  baseline_config.task_prefix_2 = \">>ast<< \"\n",
    "  baseline_config.num_beams = 4\n",
    "  # baseline_config.batch_size = 1 #not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Gt2BTByILsnr",
   "metadata": {
    "id": "Gt2BTByILsnr"
   },
   "outputs": [],
   "source": [
    "def translate(batch): # might need to update later on for trained model\n",
    "  inputs = [baseline_config.task_prefix + x for x in batch['es']]\n",
    "\n",
    "  encoded = tokenizer(\n",
    "      inputs,\n",
    "      max_length=baseline_config.model_max_length,\n",
    "      truncation=True,\n",
    "      padding=True,\n",
    "      return_tensors=\"pt\"\n",
    "  )\n",
    "  input_ids = encoded.input_ids.to(config.device)\n",
    "  attention = encoded.attention_mask.to(config.device)\n",
    "\n",
    "  output = model.generate(\n",
    "      input_ids = input_ids,\n",
    "      attention_mask = attention,\n",
    "      num_beams=baseline_config.num_beams,\n",
    "      max_length=baseline_config.model_max_length,\n",
    "  )\n",
    "\n",
    "  decoded = tokenizer.batch_decode(\n",
    "      sequences=output,\n",
    "      skip_special_tokens=True\n",
    "  )\n",
    "\n",
    "  targets = [[x] for x in batch['ast']]\n",
    "  return {\n",
    "      \"reference\": targets,\n",
    "      \"prediction\": decoded\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GRa7hPYuvgTM",
   "metadata": {
    "id": "GRa7hPYuvgTM"
   },
   "outputs": [],
   "source": [
    "# test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nrwRA21Ah-TJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "fb9e0350ebf247318e20979e85bc1907",
      "62e3cf1259ed44ed9b063fccd36ce96e",
      "31be9aaef22046559178aba09403c916",
      "4a54277e4fe74739bc2303195bf7d1a8",
      "9eac8725454b42f9a32dffd0f45aaec8",
      "bf0fc514bd2a474aba5d5450545ce847",
      "a0400bb100f34e8caeb0e680eab0db5e",
      "7edf35aca54f43628e6596d383f5c057",
      "bf484be7370a4c24b0ca151b2502db7c",
      "8bc6f17f7af64bf8932a2045b428a65b",
      "4be36d322d1f4f33a995776e04ae78f8"
     ]
    },
    "id": "nrwRA21Ah-TJ",
    "outputId": "b0f4d07b-4188-4de6-fdec-3cf446b17b66"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9e0350ebf247318e20979e85bc1907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/997 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if baseline:\n",
    "  results = dev_ds.map(\n",
    "    translate,\n",
    "    batched=True,\n",
    "    batch_size=30,\n",
    "    remove_columns=dev_ds.column_names)\n",
    "\n",
    "  metric = evaluate.load(\"sacrebleu\")\n",
    "  chrf = evaluate.load(\"chrf\")\n",
    "\n",
    "  for r in results:\n",
    "    prediction = r['prediction']\n",
    "    reference = r['reference']\n",
    "    metric.add(prediction=prediction, reference=reference)\n",
    "    chrf.add(prediction=prediction, reference=reference)\n",
    "\n",
    "  bleu = metric.compute()\n",
    "  chr2 = chrf.compute(word_order=2)\n",
    "\n",
    "  results = {'bleu': bleu['score']}\n",
    "  results['chrf2'] = chr2['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Wrjajk4bBZxm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wrjajk4bBZxm",
    "outputId": "e1c63fb4-455c-4f49-8a36-75ad64cb95e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 8.647230329801756, 'chrf2': 39.55321473399512}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be8c2f5",
   "metadata": {
    "id": "2be8c2f5"
   },
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QOg0l-tCkgbo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QOg0l-tCkgbo",
    "outputId": "c3d7fbe1-29f8-42f9-eab9-b89045806edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device cuda is being used.\n"
     ]
    }
   ],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h1bwv30AkjwK",
   "metadata": {
    "id": "h1bwv30AkjwK"
   },
   "outputs": [],
   "source": [
    "config.model_checkpoint = 'Helsinki-NLP/opus-mt-tc-bible-big-deu_eng_fra_por_spa-itc'\n",
    "config.source_lang = 'es'\n",
    "config.target_lang = 'ast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yroWfche-04L",
   "metadata": {
    "id": "yroWfche-04L"
   },
   "outputs": [],
   "source": [
    "model_config = MarianConfig.from_pretrained(config.model_checkpoint)\n",
    "tokenizer = MarianTokenizer.from_pretrained(config.model_checkpoint)\n",
    "model_checkpoint = MarianMTModel.from_pretrained(config.model_checkpoint, config=model_config)\n",
    "model_checkpoint.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "E1bf9rxGk8Oh",
   "metadata": {
    "id": "E1bf9rxGk8Oh"
   },
   "outputs": [],
   "source": [
    "config.model_max_length = tokenizer.model_max_length\n",
    "config.max_source_length = tokenizer.model_max_length\n",
    "config.max_target_length = tokenizer.model_max_length\n",
    "config.label_pad_token_id = tokenizer.pad_token_id\n",
    "config.task_prefix = \">>spa<< \"\n",
    "config.task_prefix_2 = \">>ast<< \"\n",
    "config.num_beams = 4\n",
    "config.batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391f8f6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "391f8f6f",
    "outputId": "e628cd05-62bb-4051-ce85-0f00bcea2ec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 224993280\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of parameters: {model_checkpoint.num_parameters()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rp6Q-wMUth-G",
   "metadata": {
    "id": "rp6Q-wMUth-G"
   },
   "outputs": [],
   "source": [
    "# from peft import PeftModelForSeq2SeqLM, get_peft_config #maybe not use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D7XnLq4HsWZt",
   "metadata": {
    "id": "D7XnLq4HsWZt"
   },
   "outputs": [],
   "source": [
    "# lora_config = {\n",
    "#     \"peft_type\": \"LORA\",\n",
    "#     \"task_type\": \"SEQ_2_SEQ_LM\",\n",
    "#     \"r\": 64, # not much difference in training time... fine-tune full model?\n",
    "#     \"target_modules\": [\"q_proj\", \"v_proj\", \"q_proj\"],\n",
    "#     \"lora_alpha\": 32, #fix to 16\n",
    "#     \"fan_in_fan_out\": False,\n",
    "#     \"bias\": \"none\",\n",
    "#     \"lora_dropout\": 0.1\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OpTpNYPCuLH6",
   "metadata": {
    "id": "OpTpNYPCuLH6"
   },
   "outputs": [],
   "source": [
    "# peft_config = get_peft_config(lora_config)\n",
    "# peft_model = PeftModelForSeq2SeqLM(model_checkpoint, peft_config)\n",
    "# peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zeR0cGSCo2Gc",
   "metadata": {
    "id": "zeR0cGSCo2Gc"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "  preds, labels = eval_preds\n",
    "\n",
    "  preds = np.where(\n",
    "      preds != -100,\n",
    "      preds,\n",
    "      tokenizer.pad_token_id\n",
    "  )\n",
    "\n",
    "  predictions = tokenizer.batch_decode(\n",
    "      preds,\n",
    "      skip_special_tokens=True)\n",
    "\n",
    "  labels = np.where(\n",
    "      labels != -100,\n",
    "      labels,\n",
    "      tokenizer.pad_token_id)\n",
    "\n",
    "  references = tokenizer.batch_decode(\n",
    "      labels,\n",
    "      skip_special_tokens=True)\n",
    "\n",
    "  references = [[ref] for ref in references]\n",
    "\n",
    "  results = sacrebleu_score.compute(predictions=predictions, references=references)\n",
    "  results = {'sacrebleu': results['score']}\n",
    "\n",
    "  prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "  results['gen_len'] = np.mean(prediction_lens)\n",
    "\n",
    "  chrf_sc = chrf.compute(predictions=predictions, references=references, word_order=2, lowercase=True)\n",
    "  results['chrf2'] = chrf_sc['score']\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d7406",
   "metadata": {
    "id": "124d7406"
   },
   "outputs": [],
   "source": [
    "def preprocess_fn(batch): # task prefix\n",
    "    sources = batch[config.source_lang]\n",
    "    sources = [config.task_prefix + x for x in sources]\n",
    "    targets = batch[config.target_lang]\n",
    "    targets = [config.task_prefix_2 + x for x in targets]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        sources,\n",
    "        max_length=config.max_source_length,\n",
    "        truncation=True,\n",
    "        # return_tensors='pt'\n",
    "        )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        targets,\n",
    "        max_length=config.max_target_length,\n",
    "        truncation=True)\n",
    "\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bf45d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "1fe7cc6f5ed6450ca24edb00ae9fc715",
      "cfb26b6f6fdb44a5a98737dbaddd6a87",
      "0c887283740f491a9cd193d4c94182d4",
      "bc70997c74bd401e87ce9a32547cf434",
      "5ef2412ea9ab404699318f537da3400b",
      "552208a4197a48a09fc074bbe60183b9",
      "2c5dc22e5d08485892b3d9174e9a2dfc",
      "7dc6793ea9604c92bceabbb40fe72191",
      "faf152f3679e428dbb168bbf69fbf415",
      "be313f2e09bc49f389f2ebbfc2b66459",
      "79a046a88f1542c9a82d0ee072e14553",
      "fb096af892bf4e12aa841c0845f70b87",
      "aea2d3c7f44b4769bb265b7ef4ba1cfb",
      "c9c01e9c083d4c65baf1f605b546b8d2",
      "8e27b4de9c61488c966ac3e82889da9c",
      "d99c7e910fbf47a098ffc8a9ee329b81",
      "0614ce0da1a744c7a99181bd5ab6f21b",
      "a1d1b3bd29844c7698e12caeeff0ce0a",
      "afa4a2c6e89e4fc190beedd482e0a885",
      "c75f5b192ce247dfbf5a68809d49c80d",
      "07ece78f73374547947b219f47402ff2",
      "ffc3a11cbefd49b29f29720fab1bd3d8",
      "abe128af233e47ba9e7bcd8fb6010b3b",
      "43cb6cbc22c8473cbc7fa1e36466acf2",
      "2ee285f02ad045f584d875a2249d5a6d",
      "3e986591eeed4b35a1d2b4781cfab954",
      "7325475d2b414e6f87e701e4e6a8f002",
      "3a3c38dd1c2740e4b665012511257643",
      "b02c5b6fd19e49fd993bc4b3b9f554f4",
      "159f018664d845bda12d1e5f246504cd",
      "1762b47b59a84efa81112d3d4fd1c547",
      "aee31799ea234b34a07e0bd042f2cfc2",
      "299011cbd0184d23883f24c0afa2ccf9"
     ]
    },
    "id": "89bf45d2",
    "outputId": "0941c4c5-5688-4e1b-eae4-5100603d263d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe7cc6f5ed6450ca24edb00ae9fc715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/122449 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb096af892bf4e12aa841c0845f70b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/997 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe128af233e47ba9e7bcd8fb6010b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dict = dataset_dict.map(\n",
    "    preprocess_fn,\n",
    "    batched=True,\n",
    "    remove_columns=dataset_dict['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460abf5",
   "metadata": {
    "id": "8460abf5"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model_checkpoint,\n",
    "    label_pad_token_id=config.label_pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urxmSws3aX5T",
   "metadata": {
    "id": "urxmSws3aX5T"
   },
   "outputs": [],
   "source": [
    "config.save_steps = 500 # 4_500 4_000\n",
    "config.lr = 5e-4\n",
    "config.weight_decay = 0.001\n",
    "config.num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mnHKiJOY4KpS",
   "metadata": {
    "id": "mnHKiJOY4KpS"
   },
   "outputs": [],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=fine_tuned_model_checkpoint,\n",
    "    seed = config.seed,\n",
    "    auto_find_batch_size = True,\n",
    "    do_train = config.do_train,\n",
    "    logging_steps = config.save_steps,\n",
    "    eval_strategy =\"steps\",\n",
    "    eval_steps = config.save_steps,\n",
    "    save_steps = config.save_steps,\n",
    "    save_total_limit = 3,\n",
    "    report_to = \"wandb\",\n",
    "    predict_with_generate = True,\n",
    "    gradient_accumulation_steps=8, # reduce? 8 -> 4\n",
    "    learning_rate = config.lr, # 5e-5, # default, config.lr, # toggle.. 5e-4 problematic?\n",
    "    weight_decay = config.weight_decay,\n",
    "    num_train_epochs = config.num_epochs,\n",
    "    generation_num_beams = config.num_beams,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b34f55e",
   "metadata": {
    "id": "9b34f55e"
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model_checkpoint,\n",
    "    args=args,\n",
    "    train_dataset=dataset_dict['train'],\n",
    "    eval_dataset=dataset_dict['dev'],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    #early stopping and load best model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DpjnxxGmEdYM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DpjnxxGmEdYM",
    "outputId": "63181e13-5334-43b7-9556-f9e0d491fb2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint detected. Resuming training at ./gdrive/MyDrive/translation/opus-mt-tc-bible-big-deu_eng_fra_por_spa-itc_en-es/checkpoint/checkpoint-2000\n"
     ]
    }
   ],
   "source": [
    "last_checkpoint = None\n",
    "\n",
    "if os.path.isdir(fine_tuned_model_checkpoint):\n",
    "  last_checkpoint = get_last_checkpoint(fine_tuned_model_checkpoint)\n",
    "\n",
    "if last_checkpoint is not None:\n",
    "  print(f\"Checkpoint detected. Resuming training at {last_checkpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JMEhFPSW3p4j",
   "metadata": {
    "id": "JMEhFPSW3p4j"
   },
   "outputs": [],
   "source": [
    "last_checkpoint=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RizLJVov6zin",
   "metadata": {
    "id": "RizLJVov6zin"
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sbDRFX9sCuOQ",
   "metadata": {
    "id": "sbDRFX9sCuOQ"
   },
   "outputs": [],
   "source": [
    "# rm = '/content/gdrive/MyDrive/translation/opus-mt-tc-bible-big-mul-mul_en-es'\n",
    "# shutil.rmtree(rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sGEQoWKFEqqL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "sGEQoWKFEqqL",
    "outputId": "b039e22d-fb60-458f-aca2-2061240f4f01"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5739' max='5739' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5739/5739 2:52:18, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Sacrebleu</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Chrf2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.337100</td>\n",
       "      <td>2.193467</td>\n",
       "      <td>27.254522</td>\n",
       "      <td>47.599799</td>\n",
       "      <td>48.658248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>2.063804</td>\n",
       "      <td>27.763000</td>\n",
       "      <td>47.261785</td>\n",
       "      <td>49.416948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.303200</td>\n",
       "      <td>2.147596</td>\n",
       "      <td>28.024178</td>\n",
       "      <td>47.202608</td>\n",
       "      <td>49.631045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.274300</td>\n",
       "      <td>2.106616</td>\n",
       "      <td>27.926571</td>\n",
       "      <td>47.616851</td>\n",
       "      <td>49.874724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.248800</td>\n",
       "      <td>1.997771</td>\n",
       "      <td>28.204162</td>\n",
       "      <td>47.637914</td>\n",
       "      <td>50.143117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.234400</td>\n",
       "      <td>1.957083</td>\n",
       "      <td>28.355529</td>\n",
       "      <td>47.405216</td>\n",
       "      <td>50.285223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.219400</td>\n",
       "      <td>1.941396</td>\n",
       "      <td>28.409923</td>\n",
       "      <td>47.507523</td>\n",
       "      <td>50.343122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>1.915902</td>\n",
       "      <td>28.643310</td>\n",
       "      <td>47.473420</td>\n",
       "      <td>50.502605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.167900</td>\n",
       "      <td>1.893328</td>\n",
       "      <td>28.539495</td>\n",
       "      <td>47.498495</td>\n",
       "      <td>50.550013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.162600</td>\n",
       "      <td>1.845672</td>\n",
       "      <td>28.685795</td>\n",
       "      <td>47.547643</td>\n",
       "      <td>50.589147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>1.833894</td>\n",
       "      <td>28.599793</td>\n",
       "      <td>47.439318</td>\n",
       "      <td>50.610281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed training time 10341.264021293999\n"
     ]
    }
   ],
   "source": [
    "if trainer.args.do_train:\n",
    "  start_time = perf_counter()\n",
    "  train_result = trainer.train(resume_from_checkpoint=last_checkpoint)\n",
    "  end_time = perf_counter()\n",
    "\n",
    "  print(f\"Elapsed training time {end_time - start_time}\")\n",
    "  trainer.save_model(fine_tuned_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-AvE_0D3nPgs",
   "metadata": {
    "id": "-AvE_0D3nPgs"
   },
   "outputs": [],
   "source": [
    "metrics = train_result.metrics\n",
    "metrics['train_samples'] = len(dataset_dict['train'])\n",
    "trainer.save_metrics('train', metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aIW6kDYan8a-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIW6kDYan8a-",
    "outputId": "6ce79fe8-09ea-4764-f977-07cd0f45ddc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "997"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_dict['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D4CcsH4jncTf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "D4CcsH4jncTf",
    "outputId": "3352d2e1-957d-42b2-cdb7-cae329b72105"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='377' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 38:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                    =     2.9998\n",
      "  eval__chrf2              =    50.6592\n",
      "  eval__gen_len            =    47.4965\n",
      "  eval__loss               =     1.8201\n",
      "  eval__runtime            = 0:03:36.46\n",
      "  eval__sacrebleu          =    28.6593\n",
      "  eval__samples_per_second =      4.606\n",
      "  eval__steps_per_second   =      0.577\n",
      "  eval_samples             =        997\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(\n",
    "    max_length=tokenizer.model_max_length,\n",
    "    num_beams=config.num_beams,\n",
    "    metric_key_prefix=\"eval_\",\n",
    ")\n",
    "\n",
    "metrics['eval_samples'] = len(dataset_dict['dev'])\n",
    "\n",
    "trainer.log_metrics('eval', metrics)\n",
    "trainer.save_metrics('eval', metrics)\n",
    "trainer.save_state()  # Ensures trainer state is saved SEE HERE AGAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AWBcqtvayIcG",
   "metadata": {
    "id": "AWBcqtvayIcG"
   },
   "outputs": [],
   "source": [
    "trainer.state.log_history[-1][\"eval_samples\"] = len(dataset_dict['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "avq-Wj5YpSpW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avq-Wj5YpSpW",
    "outputId": "d043e2a5-b3c7-4b2a-bf83-43e52cc3ab2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval__loss': 1.8201063871383667,\n",
       " 'eval__sacrebleu': 28.659270382358148,\n",
       " 'eval__gen_len': 47.496489468405215,\n",
       " 'eval__chrf2': 50.65921542296703,\n",
       " 'eval__runtime': 216.4626,\n",
       " 'eval__samples_per_second': 4.606,\n",
       " 'eval__steps_per_second': 0.577,\n",
       " 'epoch': 2.999804011236689,\n",
       " 'step': 5739,\n",
       " 'eval_samples': 997}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bxkxauzxpadQ",
   "metadata": {
    "id": "bxkxauzxpadQ"
   },
   "outputs": [],
   "source": [
    "devtest_ast = load_dataset('text', data_files='gdrive/MyDrive/translation/FLORES+/devtest/devtest.ast_Latn', split='train')\n",
    "devtest_spa = load_dataset('text', data_files='gdrive/MyDrive/translation/FLORES+/devtest/devtest.spa_Latn', split='train')\n",
    "# devtest = concatenate_datasets([devtest_spa, devtest_ast], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZIAsMXnhpppI",
   "metadata": {
    "id": "ZIAsMXnhpppI"
   },
   "outputs": [],
   "source": [
    "devtest_ast = devtest_ast.rename_column('text', 'ast')\n",
    "devtest_spa = devtest_spa.rename_column('text', 'es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sJyEVmYJp85g",
   "metadata": {
    "id": "sJyEVmYJp85g"
   },
   "outputs": [],
   "source": [
    "test_ds = concatenate_datasets([devtest_spa, devtest_ast], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saW8a2pSqwHF",
   "metadata": {
    "id": "saW8a2pSqwHF"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z-IwO0jwq9_V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-IwO0jwq9_V",
    "outputId": "2e50a4c3-402e-454c-8f50-17b9e61b73fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['es', 'ast'],\n",
       "    num_rows: 1012\n",
       "})"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Tjx22-iysJsf",
   "metadata": {
    "id": "Tjx22-iysJsf"
   },
   "outputs": [],
   "source": [
    "dataset_dict = dataset_dict.map(\n",
    "    preprocess_fn,\n",
    "    batched=True,\n",
    "    remove_columns=dataset_dict['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oF3ni2cMrKY2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c03637383a444df08dadf42503e51e8c",
      "f43528fc72284fb98748d2069319bb7f",
      "78f7458f4b024ecca45b861d58e12d9c",
      "ec9b94af66c1496c8fc1e7eeb20c4c28",
      "471fa04f302d4ae992769f556b85b4eb",
      "e124be6144a54270a999ff081256be76",
      "b926667bb2ab4e03adb1b21f319552a6",
      "54a8cff41ab1479db959fa8666540516",
      "8e4c7d87958d42d6806928b3551743b6",
      "3c979490227f4c07b941527af9e63bad",
      "3298a8076bae437c975b18e7430017e7"
     ]
    },
    "id": "oF3ni2cMrKY2",
    "outputId": "85386a1d-774d-402a-db7c-a26e20122f6e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03637383a444df08dadf42503e51e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ds = test_ds.map(\n",
    "    preprocess_fn,\n",
    "    batched=True,\n",
    "    remove_columns=test_ds.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xgf-hAqCrvv1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "xgf-hAqCrvv1",
    "outputId": "9a38a59a-9f57-4f9c-e0ce-48542cc941f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 21:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = trainer.evaluate(\n",
    "    eval_dataset=test_ds,\n",
    "    max_length=tokenizer.model_max_length,\n",
    "    num_beams=config.num_beams,\n",
    "    metric_key_prefix=\"test_\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9zbtwQcTsW-t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zbtwQcTsW-t",
    "outputId": "141235e0-bf16-43b4-ce03-32890a784f11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** test metrics *****\n",
      "  epoch                    =     2.9998\n",
      "  test__chrf2              =    50.6823\n",
      "  test__gen_len            =    49.7826\n",
      "  test__loss               =      1.842\n",
      "  test__runtime            = 0:03:57.53\n",
      "  test__sacrebleu          =    28.0745\n",
      "  test__samples_per_second =       4.26\n",
      "  test__steps_per_second   =      0.535\n",
      "  test_samples             =       1012\n"
     ]
    }
   ],
   "source": [
    "metrics['test_samples'] = len(test_ds)\n",
    "\n",
    "trainer.log_metrics('test', metrics)\n",
    "trainer.save_metrics('test', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LH2uf7k2uBwZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LH2uf7k2uBwZ",
    "outputId": "c3ba3e1b-5899-4dd4-da58-ac88d544551c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.3371,\n",
       "  'grad_norm': 0.9933468103408813,\n",
       "  'learning_rate': 0.00045643840390311905,\n",
       "  'epoch': 0.26131835108120466,\n",
       "  'step': 500},\n",
       " {'eval_loss': 2.193467378616333,\n",
       "  'eval_sacrebleu': 27.25452244063354,\n",
       "  'eval_gen_len': 47.599799398194584,\n",
       "  'eval_chrf2': 48.65824783386484,\n",
       "  'eval_runtime': 213.7513,\n",
       "  'eval_samples_per_second': 4.664,\n",
       "  'eval_steps_per_second': 0.585,\n",
       "  'epoch': 0.26131835108120466,\n",
       "  'step': 500},\n",
       " {'loss': 0.325,\n",
       "  'grad_norm': 1.225108027458191,\n",
       "  'learning_rate': 0.00041287680780623803,\n",
       "  'epoch': 0.5226367021624093,\n",
       "  'step': 1000},\n",
       " {'eval_loss': 2.0638043880462646,\n",
       "  'eval_sacrebleu': 27.762999896365063,\n",
       "  'eval_gen_len': 47.2617853560682,\n",
       "  'eval_chrf2': 49.41694779322967,\n",
       "  'eval_runtime': 216.2414,\n",
       "  'eval_samples_per_second': 4.611,\n",
       "  'eval_steps_per_second': 0.578,\n",
       "  'epoch': 0.5226367021624093,\n",
       "  'step': 1000},\n",
       " {'loss': 0.3032,\n",
       "  'grad_norm': 1.1556296348571777,\n",
       "  'learning_rate': 0.0003693152117093571,\n",
       "  'epoch': 0.783955053243614,\n",
       "  'step': 1500},\n",
       " {'eval_loss': 2.1475963592529297,\n",
       "  'eval_sacrebleu': 28.02417750210974,\n",
       "  'eval_gen_len': 47.20260782347041,\n",
       "  'eval_chrf2': 49.631044943579425,\n",
       "  'eval_runtime': 216.2587,\n",
       "  'eval_samples_per_second': 4.61,\n",
       "  'eval_steps_per_second': 0.578,\n",
       "  'epoch': 0.783955053243614,\n",
       "  'step': 1500},\n",
       " {'loss': 0.2743,\n",
       "  'grad_norm': 1.5079734325408936,\n",
       "  'learning_rate': 0.00032575361561247606,\n",
       "  'epoch': 1.0454693930881296,\n",
       "  'step': 2000},\n",
       " {'eval_loss': 2.106616258621216,\n",
       "  'eval_sacrebleu': 27.926570942191802,\n",
       "  'eval_gen_len': 47.61685055165496,\n",
       "  'eval_chrf2': 49.8747240573074,\n",
       "  'eval_runtime': 212.1977,\n",
       "  'eval_samples_per_second': 4.698,\n",
       "  'eval_steps_per_second': 0.589,\n",
       "  'epoch': 1.0454693930881296,\n",
       "  'step': 2000},\n",
       " {'loss': 0.2488,\n",
       "  'grad_norm': 0.8264591693878174,\n",
       "  'learning_rate': 0.00028219201951559504,\n",
       "  'epoch': 1.3067877441693343,\n",
       "  'step': 2500},\n",
       " {'eval_loss': 1.9977706670761108,\n",
       "  'eval_sacrebleu': 28.2041618002025,\n",
       "  'eval_gen_len': 47.63791374122367,\n",
       "  'eval_chrf2': 50.143116993300104,\n",
       "  'eval_runtime': 211.642,\n",
       "  'eval_samples_per_second': 4.711,\n",
       "  'eval_steps_per_second': 0.591,\n",
       "  'epoch': 1.3067877441693343,\n",
       "  'step': 2500},\n",
       " {'loss': 0.2344,\n",
       "  'grad_norm': 0.77372145652771,\n",
       "  'learning_rate': 0.00023863042341871408,\n",
       "  'epoch': 1.568106095250539,\n",
       "  'step': 3000},\n",
       " {'eval_loss': 1.9570825099945068,\n",
       "  'eval_sacrebleu': 28.35552868056268,\n",
       "  'eval_gen_len': 47.405215646940825,\n",
       "  'eval_chrf2': 50.2852226260234,\n",
       "  'eval_runtime': 216.2947,\n",
       "  'eval_samples_per_second': 4.609,\n",
       "  'eval_steps_per_second': 0.578,\n",
       "  'epoch': 1.568106095250539,\n",
       "  'step': 3000},\n",
       " {'loss': 0.2194,\n",
       "  'grad_norm': 0.614846408367157,\n",
       "  'learning_rate': 0.00019506882732183307,\n",
       "  'epoch': 1.8294244463317435,\n",
       "  'step': 3500},\n",
       " {'eval_loss': 1.941395878791809,\n",
       "  'eval_sacrebleu': 28.40992316394004,\n",
       "  'eval_gen_len': 47.50752256770311,\n",
       "  'eval_chrf2': 50.34312193337044,\n",
       "  'eval_runtime': 233.6546,\n",
       "  'eval_samples_per_second': 4.267,\n",
       "  'eval_steps_per_second': 0.535,\n",
       "  'epoch': 1.8294244463317435,\n",
       "  'step': 3500},\n",
       " {'loss': 0.1999,\n",
       "  'grad_norm': 0.6166176199913025,\n",
       "  'learning_rate': 0.00015150723122495208,\n",
       "  'epoch': 2.090938786176259,\n",
       "  'step': 4000},\n",
       " {'eval_loss': 1.915901780128479,\n",
       "  'eval_sacrebleu': 28.643309946644475,\n",
       "  'eval_gen_len': 47.47342026078235,\n",
       "  'eval_chrf2': 50.50260519414774,\n",
       "  'eval_runtime': 223.0045,\n",
       "  'eval_samples_per_second': 4.471,\n",
       "  'eval_steps_per_second': 0.561,\n",
       "  'epoch': 2.090938786176259,\n",
       "  'step': 4000},\n",
       " {'loss': 0.1679,\n",
       "  'grad_norm': 0.48438259959220886,\n",
       "  'learning_rate': 0.00010794563512807109,\n",
       "  'epoch': 2.352257137257464,\n",
       "  'step': 4500},\n",
       " {'eval_loss': 1.893328070640564,\n",
       "  'eval_sacrebleu': 28.53949526535115,\n",
       "  'eval_gen_len': 47.498495486459376,\n",
       "  'eval_chrf2': 50.550013132887294,\n",
       "  'eval_runtime': 216.5451,\n",
       "  'eval_samples_per_second': 4.604,\n",
       "  'eval_steps_per_second': 0.577,\n",
       "  'epoch': 2.352257137257464,\n",
       "  'step': 4500},\n",
       " {'loss': 0.1626,\n",
       "  'grad_norm': 0.39347320795059204,\n",
       "  'learning_rate': 6.43840390311901e-05,\n",
       "  'epoch': 2.6135754883386686,\n",
       "  'step': 5000},\n",
       " {'eval_loss': 1.8456716537475586,\n",
       "  'eval_sacrebleu': 28.685795286060234,\n",
       "  'eval_gen_len': 47.54764292878636,\n",
       "  'eval_chrf2': 50.58914665685096,\n",
       "  'eval_runtime': 215.8456,\n",
       "  'eval_samples_per_second': 4.619,\n",
       "  'eval_steps_per_second': 0.579,\n",
       "  'epoch': 2.6135754883386686,\n",
       "  'step': 5000},\n",
       " {'loss': 0.1542,\n",
       "  'grad_norm': 0.5078829526901245,\n",
       "  'learning_rate': 2.0822442934309112e-05,\n",
       "  'epoch': 2.8748938394198733,\n",
       "  'step': 5500},\n",
       " {'eval_loss': 1.8338936567306519,\n",
       "  'eval_sacrebleu': 28.599793181141987,\n",
       "  'eval_gen_len': 47.43931795386158,\n",
       "  'eval_chrf2': 50.610280782210026,\n",
       "  'eval_runtime': 215.3073,\n",
       "  'eval_samples_per_second': 4.631,\n",
       "  'eval_steps_per_second': 0.581,\n",
       "  'epoch': 2.8748938394198733,\n",
       "  'step': 5500},\n",
       " {'train_runtime': 10340.1145,\n",
       "  'train_samples_per_second': 35.526,\n",
       "  'train_steps_per_second': 0.555,\n",
       "  'total_flos': 2.936122597756109e+16,\n",
       "  'train_loss': 0.23557593503009153,\n",
       "  'epoch': 2.999804011236689,\n",
       "  'step': 5739},\n",
       " {'eval__loss': 1.8201063871383667,\n",
       "  'eval__sacrebleu': 28.659270382358148,\n",
       "  'eval__gen_len': 47.496489468405215,\n",
       "  'eval__chrf2': 50.65921542296703,\n",
       "  'eval__runtime': 217.257,\n",
       "  'eval__samples_per_second': 4.589,\n",
       "  'eval__steps_per_second': 0.575,\n",
       "  'epoch': 2.999804011236689,\n",
       "  'step': 5739},\n",
       " {'test__loss': 1.8420054912567139,\n",
       "  'test__sacrebleu': 28.07450933537276,\n",
       "  'test__gen_len': 49.78260869565217,\n",
       "  'test__chrf2': 50.68229143623657,\n",
       "  'test__runtime': 237.531,\n",
       "  'test__samples_per_second': 4.26,\n",
       "  'test__steps_per_second': 0.535,\n",
       "  'epoch': 2.999804011236689,\n",
       "  'step': 5739}]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qVFcMDCRRdr8",
   "metadata": {
    "id": "qVFcMDCRRdr8"
   },
   "source": [
    "## ?. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cQSQgEIZRJGh",
   "metadata": {
    "id": "cQSQgEIZRJGh"
   },
   "outputs": [],
   "source": [
    "#0. save metrics\n",
    "#1. trainer.evaluate()\n",
    "# 2. generate_translation()\n",
    "#save kwargs\n",
    "#trainer.create_model_card()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3wRVRVEByctL",
   "metadata": {
    "id": "3wRVRVEByctL"
   },
   "outputs": [],
   "source": [
    "output_dir = '/content/gdrive/MyDrive/translation/opus-mt-tc-bible-big-deu_eng_fra_por_spa-itc_en-es/checkpoint/checkpoint-5739'\n",
    "tokenizer = MarianTokenizer.from_pretrained(\n",
    "output_dir,\n",
    "local_files_only=True,\n",
    ")\n",
    "model = MarianMTModel.from_pretrained(\n",
    "output_dir,\n",
    "local_files_only=True,\n",
    ")\n",
    "model = model.to(device)\n",
    "# maybe clean up (again) and then continue training\n",
    "# test hypothesis on Galician / model"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
